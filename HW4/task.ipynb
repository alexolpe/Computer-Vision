{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.ndimage import maximum_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Open an image file\n",
    "with Image.open('/home/aolivepe/Computer-Vision/HW4/my_images/tv_2.jpg') as imagege:\n",
    "    # Resize the image to 500x500\n",
    "    resized_image = image.resize((500, 500))\n",
    "\n",
    "    # Save the resized image\n",
    "    resized_imagege.save('/home/aolivepe/Computer-Vision/HW4/HW4_images/tv_2.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw points\n",
    "def putPointsOnImage(corners, image):\n",
    "    for corner in corners:\n",
    "        cv2.circle(image, tuple(corner), radius=5, color=(42, 247, 237), thickness =-1)\n",
    "    return image\n",
    "    \n",
    "# Function to draw points and lines\n",
    "def putPointsAndLinesOnImage(final_image, w, selected, p1, corners2):\n",
    "    points_1=(p1)\n",
    "    points_2 = (corners2[selected] + np.array([w, 0]))\n",
    "    cv2.circle(final_image, points_1, radius=5, color = (42, 247, 237), thickness=-1)\n",
    "    cv2.circle(final_image, points_2, radius = 5, color=(42, 247, 237), thickness =-1)\n",
    "    cv2.line(final_image,points_1,points_2,(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)), 1)\n",
    "    return final_image\n",
    "\n",
    "# Function to get the Harris response\n",
    "def getHarrisResponse(dx, dy, N):\n",
    "    s_dxdx = cv2.filter2D(dx*dx, ddepth=-1, kernel=np.ones((N,N)))\n",
    "    s_dydy = cv2.filter2D(dy*dy, ddepth=-1, kernel=np.ones((N,N)))\n",
    "    s_dxdy = cv2.filter2D(dx*dy, ddepth=-1, kernel=np.ones((N,N)))\n",
    "    #Compute the trace and determinant\n",
    "    tr_c = s_dxdx + s_dydy\n",
    "    det_c = (s_dxdx*s_dydy)-(s_dxdy*s_dxdy)\n",
    "    return det_c-0.05*(tr_c**2)\n",
    "    \n",
    "def harris_detect_corner(image, sig):\n",
    "    #Get gray scale image\n",
    "    gray_scale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)/255\n",
    "    \n",
    "    # Build Haar filter\n",
    "    M = int(np.ceil(4*sig))\n",
    "    if M%2 == 1:\n",
    "        M = M + 1\n",
    "    haar_x = np.zeros((M, M))\n",
    "    haar_x[:, :M // 2] = -1\n",
    "    haar_x[:, M // 2:] = 1\n",
    "    haar_y = np.zeros((M, M))\n",
    "    haar_y[:M // 2, :] = 1\n",
    "    haar_y[M // 2:, :] = -1\n",
    "    \n",
    "    # Get dx and dy by applying Haar filter in both directions\n",
    "    dx = cv2.filter2D(gray_scale_image, ddepth = -1, kernel = haar_x)\n",
    "    dy = cv2.filter2D(gray_scale_image, ddepth = -1, kernel = haar_y)\n",
    "    \n",
    "    #Get Harris response and set threshold\n",
    "    N = int(np.ceil(5*sig))\n",
    "    if N%2 == 1:\n",
    "        N = N + 1\n",
    "    H = getHarrisResponse(dx, dy, N)\n",
    "    R_abs = np.abs(H)\n",
    "    thr = np.mean(R_abs)\n",
    "    K = 2*N\n",
    "    \n",
    "    #Apply maximum filter to get local max values in (2K+1, 2K+1) windows\n",
    "    R_max_window = maximum_filter(H, size=(2*K+1, 2*K+1))\n",
    "    #Create a boolean mask where the current pixel is the max in its window and exceeds threshold\n",
    "    max_mask = (H == R_max_window) & (H > thr)\n",
    "    #Find the coordinates of the corners\n",
    "    y_coords, x_coords = np.nonzero(max_mask)\n",
    "    #Extract the corresponding R values at those positions\n",
    "    R_values = H[y_coords, x_coords]\n",
    "    #Stack coordinates with their corresponding R values\n",
    "    corners = np.vstack((x_coords, y_coords, R_values)).T\n",
    "    #Sort corners based on the R value (descending) and take the top 100\n",
    "    corners_100 = corners[np.argsort(corners[:, 2])][-100:, :2].astype(int)\n",
    "\n",
    "    img_with_corners = putPointsOnImage(corners_100, image)\n",
    "        \n",
    "    return [corners_100, img_with_corners]\n",
    "\n",
    "def ssd(image1, image2, fake_corners_1, fake_corners_2, window):\n",
    "    #Get gray scale image\n",
    "    gray_scale_image_1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)/255\n",
    "    gray_scale_image_2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)/255\n",
    "    final_image = np.concatenate((image1, image2), axis=1)\n",
    "       \n",
    "    # We remove the pixels that do not have enough margin to get the window of pixels around them\n",
    "    corners_1 = fake_corners_1[\n",
    "        (fake_corners_1[:, 1] - window // 2 > 0) &\n",
    "        (fake_corners_1[:, 0] - window // 2 > 0) &\n",
    "        (fake_corners_1[:, 1] + window // 2 < gray_scale_image_1.shape[0]) &\n",
    "        (fake_corners_1[:, 0] + window // 2 < gray_scale_image_1.shape[1])\n",
    "    ]\n",
    "    corners_2 = fake_corners_2[\n",
    "        (fake_corners_2[:, 1] - window // 2 > 0) &\n",
    "        (fake_corners_2[:, 0] - window // 2 > 0) &\n",
    "        (fake_corners_2[:, 1] + window // 2 < gray_scale_image_2.shape[0]) &\n",
    "        (fake_corners_2[:, 0] + window // 2 < gray_scale_image_2.shape[1])\n",
    "    ]\n",
    "    \n",
    "    #Match corners similar to previous solution\n",
    "    for p1 in corners_1:\n",
    "        ssd = np.zeros((len(corners_2),2))\n",
    "        for j , p2 in enumerate ( corners_2 ):\n",
    "            image1_window = gray_scale_image_1[p1[1]-window//2:p1[1]+window//2, p1[0]-window//2:p1[0]+window//2]\n",
    "            image2_window = gray_scale_image_2[p2[1]-window//2:p2[1]+window//2, p2[0]-window//2:p2[0]+window//2]\n",
    "            ssd[j] = np.array([np.sum((image1_window-image2_window)**2),j])\n",
    "        final_image = putPointsAndLinesOnImage(final_image, image1.shape[1], np.argmin(ssd[:,0], axis=0), p1, corners_2)\n",
    "    return final_image\n",
    "\n",
    "def ncc(image1, image2, fake_corners_1, fake_corners_2, window):\n",
    "    #Get gray scale image\n",
    "    gray_scale_image_1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)/255\n",
    "    gray_scale_image_2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)/255\n",
    "    final_image = np.concatenate((image1, image2), axis=1)\n",
    "    \n",
    "    # We remove the pixels that do not have enough margin to get the window of pixels around them\n",
    "    corners_1 = fake_corners_1[\n",
    "        (fake_corners_1[:, 1] - window // 2 > 0) &\n",
    "        (fake_corners_1[:, 0] - window // 2 > 0) &\n",
    "        (fake_corners_1[:, 1] + window // 2 < gray_scale_image_1.shape[0]) &\n",
    "        (fake_corners_1[:, 0] + window // 2 < gray_scale_image_1.shape[1])\n",
    "    ]\n",
    "    corners_2 = fake_corners_2[\n",
    "        (fake_corners_2[:, 1] - window // 2 > 0) &\n",
    "        (fake_corners_2[:, 0] - window // 2 > 0) &\n",
    "        (fake_corners_2[:, 1] + window // 2 < gray_scale_image_2.shape[0]) &\n",
    "        (fake_corners_2[:, 0] + window // 2 < gray_scale_image_2.shape[1])\n",
    "    ]\n",
    "    \n",
    "    #Match corners similar to previous solution\n",
    "    for p1 in corners_1:\n",
    "        ncc = np.zeros((len(corners_2),2))\n",
    "        for j, p2 in enumerate(corners_2):\n",
    "            image1_window = gray_scale_image_1[p1[1]-window//2:p1[1]+window//2, p1[0]-window//2:p1[0]+window//2]\n",
    "            image2_window = gray_scale_image_2[p2[1]-window//2:p2[1]+window//2, p2[0]-window//2:p2[0]+window//2]\n",
    "            ncc[j] = np.array([np.sum((image1_window-np.mean(image1_window))*(image2_window-np.mean(image2_window)))/np.sqrt((np.sum((image1_window-np.mean(image1_window))**2))*(np.sum((image2_window-np.mean(image2_window))** 2))),j])\n",
    "        if np.max(ncc[:,0])>0.3:\n",
    "            selected_ncc = np.argmax(ncc[:,0], axis=0)\n",
    "        else: break\n",
    "        final_image = putPointsAndLinesOnImage(final_image, image1.shape[1], selected_ncc, p1, corners_2)\n",
    "    return final_image\n",
    "\n",
    "#Example for the hovde image. We would just change the path for the other images\n",
    "image1 = cv2.imread(\"/home/aolivepe/Computer-Vision/HW4/HW4_images/hovde_1.jpg\")\n",
    "image2 = cv2.imread(\"/home/aolivepe/Computer-Vision/HW4/HW4_images/hovde_2.jpg\")\n",
    "\n",
    "for sig in [0.8, 1.2, 1.6, 2.0]:\n",
    "    #Get corners from first image\n",
    "    corners1, h_image1 = harris_detect_corner(image1, sig)\n",
    "    cv2.imwrite(f'./output/corners_1_{str(sig)}.jpeg', h_image1)\n",
    "    \n",
    "    #Get corners from second image\n",
    "    corners2, h_image2 = harris_detect_corner(image2, sig)\n",
    "    cv2.imwrite(f'./output/corners_2_{str(sig)}.jpeg', h_image2)\n",
    "\n",
    "    #Match corners using ssd\n",
    "    ssd_final = ssd(image1, image2, corners1, corners2, 10)\n",
    "    cv2.imwrite(f'./output/ssd_{str(sig)}.jpeg', ssd_final)\n",
    "\n",
    "    #Match corners using ncc\n",
    "    ncc_final = ncc(image1, image2, corners1, corners2, 10)\n",
    "    cv2.imwrite(f'./output/ncc_{str(sig)}.jpeg', ncc_final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SIFT APPROACH\n",
    "#Example for the hovde image. We would just change the path for the other images\n",
    "image1 = cv2.imread(\"/home/aolivepe/Computer-Vision/HW4/HW4_images/hovde_1.jpg\")\n",
    "image2 = cv2.imread(\"/home/aolivepe/Computer-Vision/HW4/HW4_images/hovde_2.jpg\")\n",
    "\n",
    "# Create a SIFT detector instance\n",
    "sift_detector = cv2.SIFT_create()\n",
    "\n",
    "# Extract keypoints and vectors from both images\n",
    "kp1, vector1 = sift_detector.detectAndCompute(cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY), None)\n",
    "kp2, vector2 = sift_detector.detectAndCompute(cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY), None)\n",
    "\n",
    "# Setup the Brute Force Matcher\n",
    "raw_matches = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True).match(vector1, vector2)\n",
    "\n",
    "# Sort matches by distance\n",
    "sorted_matches = []\n",
    "for match in raw_matches:\n",
    "    sorted_matches.append(match)\n",
    "sorted_matches.sort(key=lambda m: m.distance)\n",
    "\n",
    "# Draw the top 100 matches on the images\n",
    "final_image = cv2.drawMatches(image1, kp1, image2, kp2, sorted_matches[:100], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# Construct the output file name and save the image\n",
    "cv2.imwrite(\"./output/sift.jpeg\", final_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
